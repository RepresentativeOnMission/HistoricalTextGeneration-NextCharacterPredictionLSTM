{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GA2QfCcf-Yj",
        "outputId": "3696cba7-ef60-4725-9d62-5abc55244d99"
      },
      "id": "3GA2QfCcf-Yj",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9THkDHJ5gBfC",
        "outputId": "d0abd0ce-fcf8-484d-b2da-9442154975ec"
      },
      "id": "9THkDHJ5gBfC",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.1.2-py3-none-any.whl (764 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/764.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/764.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m593.9/764.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.8/764.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.9.0 torchmetrics-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1e8dfe2b-4149-4b10-8114-5403aa77627e",
      "metadata": {
        "id": "1e8dfe2b-4149-4b10-8114-5403aa77627e"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "837a5b60-6479-4dcd-8da0-e3b28aeafbc3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "837a5b60-6479-4dcd-8da0-e3b28aeafbc3",
        "outputId": "015d2a49-a241-40bf-ce21-ba6df8f62dd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "#Load the device GPU\n",
        "gpu = torch.device(\"cuda:0\")\n",
        "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "20114766-5d9c-4d14-a1d9-ffe2b1d52f81",
      "metadata": {
        "tags": [],
        "id": "20114766-5d9c-4d14-a1d9-ffe2b1d52f81"
      },
      "outputs": [],
      "source": [
        "#load the dataset\n",
        "import codecs\n",
        "dataset_t = \"\"\n",
        "with codecs.open('/content/drive/Othercomputers/Il mio computer/BarberoGenerator/dataset/dataset_barbero_sarzana.txt', encoding='utf-8') as f:\n",
        "    for character in f:\n",
        "        dataset_t = dataset_t + character"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f58b2b63-a5ee-4522-8e3b-e0672a71f2f5",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f58b2b63-a5ee-4522-8e3b-e0672a71f2f5",
        "outputId": "f7f1fcfa-4c95-46e7-ecde-e193f5a9e6c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-c0c5f10b0c7b>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dictionary['int_encoding'] = label_enc.fit_transform(dictionary['data'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# transform dataset from numeric to one-hot\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "whole_dataset_list_of_chars = list(dataset_t)\n",
        "dataset_int = pd.DataFrame(whole_dataset_list_of_chars, columns=['data'])\n",
        "\n",
        "# create a dictionary\n",
        "label_enc = LabelEncoder()\n",
        "dictionary = dataset_int.drop_duplicates(subset=['data'])\n",
        "dictionary['int_encoding'] = label_enc.fit_transform(dictionary['data'])\n",
        "dataset_int['int_encoding'] = label_enc.fit_transform(dataset_int['data'])\n",
        "\n",
        "\n",
        "# one hot encode\n",
        "one_hot_enc = OneHotEncoder()\n",
        "# lstm uses float32 insted of float64.\n",
        "one_hot_encoded_dataset = one_hot_enc.fit_transform(dataset_int[['int_encoding']]).toarray().astype(np.float32)\n",
        "one_hot_encoded_dataset = torch.from_numpy(one_hot_encoded_dataset)\n",
        "one_hot_encoded_dataset = one_hot_encoded_dataset.to(gpu)\n",
        "print(one_hot_encoded_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3c6b005c-535e-455d-9ed7-12562d84dbde",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c6b005c-535e-455d-9ed7-12562d84dbde",
        "outputId": "56d905b9-62a5-43d6-bc89-eaf0276a7cc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        data  int_encoding\n",
            "0          b            39\n",
            "1          e            42\n",
            "2          n            51\n",
            "4                        1\n",
            "6          u            58\n",
            "...      ...           ...\n",
            "1099082    -             4\n",
            "1099618    U            33\n",
            "1100751    È            64\n",
            "1101278    N            26\n",
            "1104174    V            34\n",
            "\n",
            "[72 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "print(dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d7dc00c6-f9fe-45fc-ae9d-fa7529651a71",
      "metadata": {
        "id": "d7dc00c6-f9fe-45fc-ae9d-fa7529651a71"
      },
      "outputs": [],
      "source": [
        "# check that the device set is the GPU\n",
        "assert one_hot_encoded_dataset.get_device() == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d28b0528-4984-4602-a237-29bdd620ffa5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d28b0528-4984-4602-a237-29bdd620ffa5",
        "outputId": "ca99644b-4005-4dd7-f0a9-6bd4ae64ec87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22736\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "# ADD LABELS: turn dataset from a string \"s1,s2,...,si,si+1\" to ((s1,...,sk),(s2,...,sk+1)),...\n",
        "sequence_length = 100\n",
        "dataset = []\n",
        "for i in range(0,len(one_hot_encoded_dataset)-sequence_length,int(sequence_length/2)):\n",
        "    x = []\n",
        "    y = []\n",
        "    for j in range(sequence_length):\n",
        "        x.append(one_hot_encoded_dataset[i+j])\n",
        "        y.append(one_hot_encoded_dataset[i+j+1])\n",
        "    dataset.append((x, y))\n",
        "print(len(dataset))\n",
        "print(len(dataset[0]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We use the whole dataset as training set, bc we will use k-fold cross-validation to validate and test the models\n",
        "batch_size_train = 64\n",
        "train_dataloader = DataLoader(dataset, batch_size=batch_size_train, shuffle=False)\n",
        "iterator = iter(train_dataloader)\n",
        "print(len(iterator))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-smzGezAhIY-",
        "outputId": "a5583db3-a20f-49a0-d551-eb2abaa603fb"
      },
      "id": "-smzGezAhIY-",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "586fe12b-820e-49e5-bc0a-d826cba8e0ed",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "586fe12b-820e-49e5-bc0a-d826cba8e0ed",
        "outputId": "083e0109-597d-4f50-a2f6-539f56d1cd14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72\n"
          ]
        }
      ],
      "source": [
        "#build architecture\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        # weights and biases are initialized using the uniform distribution:\n",
        "        #      weights.uniform_(-sqrt(output_size), +sqrt(output_size))\n",
        "        self.lstm_layer = torch.nn.LSTMCell(input_size=input_size, hidden_size=hidden_size)\n",
        "        self.dense = torch.nn.Linear(in_features=hidden_size, out_features=output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = []\n",
        "        # we convert a list of tensors (given as such by the dataloader) to a tensor\n",
        "        x = torch.stack(x)\n",
        "\n",
        "        # the split function collapses the batch dimension, so now, instead of having (sequence_len,batch_size,input_size) inputs,\n",
        "        # you have a number equal to batch_size of (batch_size,input_size) inputs; you will feed these inputs one after another to the lstm, using\n",
        "        # the history h_t and short term memory c_t, along with the i-th input of type (batch_size,input_size)\n",
        "        for time_step in torch.split(x, split_size_or_sections=1, dim=0):\n",
        "            # this is needed to remove a dimension that wasn't removed by split\n",
        "            time_step = torch.squeeze(time_step)\n",
        "            h_t, c_t = self.lstm_layer(time_step)\n",
        "            output = self.dense(h_t)\n",
        "            outputs.append(output)\n",
        "        # len(outputs) = batch_size. We convert outputs to a tensor by concatenating all tensors inside it\n",
        "        #outputs = torch.stack(outputs)\n",
        "        #print(outputs.size())\n",
        "        return outputs\n",
        "input_size = 72\n",
        "output_size = input_size\n",
        "model = NeuralNetwork(input_size, 32, output_size)\n",
        "model.to(gpu)\n",
        "print(input_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ef906656-38b1-474d-bf34-361490ba4066",
      "metadata": {
        "id": "ef906656-38b1-474d-bf34-361490ba4066"
      },
      "outputs": [],
      "source": [
        "#declare loss, optimizer\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Fold Cross-Validation vs Train and Test\n",
        "How can we evaluate the differences between two different models?\n",
        "* We could train and test each of them by splitting the dataset 80/20, and confront metrics. But the split could be an unfair one.\n",
        "* We can use K-Fold <strong>Cross Validation</strong>\n",
        "\n",
        "<strong>Cross Validation</strong>: We subdivide the dataset into k GROUPS.\n",
        "* one group is selected to be the test set\n",
        "* the other groups constitutes the training set\n",
        "* the model is trained and tested, and metrics are recorded\n",
        "\n",
        "In the end we trained and tested k times the same model with different training and test sets, hence we are capable to say <strong> how good this model is, if it was to be trained with this dataset </strong>\n",
        "\n",
        "After we decided which is the best model, we will <strong> use the whole dataset to train it </strong>"
      ],
      "metadata": {
        "id": "eBK-qNnbiBmj"
      },
      "id": "eBK-qNnbiBmj"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "448f29ec-1a00-44c4-a1b6-20839348436c",
      "metadata": {
        "id": "448f29ec-1a00-44c4-a1b6-20839348436c"
      },
      "outputs": [],
      "source": [
        "#train\n",
        "def train_cycle(EPOCHS, train_dataloader, model, loss, optimizer):\n",
        "    losses = []\n",
        "    for i in range(EPOCHS):\n",
        "        iterator = iter(train_dataloader)\n",
        "        print(\"Epoch: \" + str(i))\n",
        "        for data, label in iterator:\n",
        "            # pytorch accumulate gradients at every batch, doing this you reset these gradients\n",
        "            optimizer.zero_grad()\n",
        "            #forward step\n",
        "            outputs = model(data)\n",
        "            loss_acc = 0\n",
        "            for i in range(len(outputs)):\n",
        "                loss_value = loss(outputs[i],label[i])\n",
        "                #backward step: compute gradients (apply automatic differentiation)\n",
        "                loss_value.backward()\n",
        "                loss_acc = loss_acc + loss_value\n",
        "            loss_acc = loss_acc / len(outputs)\n",
        "            losses.append(loss_acc)\n",
        "            #update the parameters using the already computed gradients\n",
        "            optimizer.step()\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "b96a1b85-6029-4854-a58d-4ba6816a99b9",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "b96a1b85-6029-4854-a58d-4ba6816a99b9"
      },
      "outputs": [],
      "source": [
        "#test\n",
        "def test_cycle(test_dataloader, model):\n",
        "  iterator = iter(test_dataloader)\n",
        "  softmax = torch.nn.Softmax(dim=1)\n",
        "  accuracies = []\n",
        "  for data, label in iterator:\n",
        "      #reshape data and label from sequence_len x num_classes\n",
        "      prediction = model(data)\n",
        "      prediction = torch.stack(prediction)\n",
        "      label = torch.stack(label)\n",
        "      #compute accuracy\n",
        "      pred_arg = torch.argmax(softmax(prediction),dim=2)\n",
        "      label_arg = torch.argmax(label,dim=2)\n",
        "      acc_list = (torch.sum(torch.eq(pred_arg, label_arg),1)/batch_size_test).tolist()\n",
        "      mean_acc = sum(acc_list)/sequence_length\n",
        "      accuracies.append(mean_acc)\n",
        "  return sum(accuracies) / len(accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# prepare cross validation\n",
        "def KFOLD(model, loss, optimizer, dataset, k):\n",
        "    batch_size_train = 64\n",
        "    batch_size_test = 128\n",
        "    kfold = KFold(k)\n",
        "    EPOCHS = 2\n",
        "    i = 0\n",
        "    mean_accuracy = []\n",
        "    for train, test in kfold.split(dataset):\n",
        "        # turn train and test folds to tensors that works with gpu\n",
        "        list_train = [dataset[i] for i in train.tolist()]\n",
        "        list_test = [dataset[i] for i in test.tolist()]\n",
        "        #tensor_train = torch.from_numpy(dataset[train])\n",
        "        #tensor_train = tensor_train.to(gpu)\n",
        "        #tensor_test = torch.from_numpy(dataset[test])\n",
        "        #tensor_test = tensor_test.to(gpu)\n",
        "        # create dataloaders for train and test folds\n",
        "        train_dataloader = DataLoader(list_train, batch_size=batch_size_train, shuffle=False)\n",
        "        test_dataloader = DataLoader(list_test, batch_size=batch_size_test, shuffle=True)\n",
        "        losses = train_cycle(EPOCHS, train_dataloader, model, loss, optimizer)\n",
        "        accuracy = test_cycle(test_dataloader, model)\n",
        "        mean_accuracy.append(accuracy)\n",
        "        print(\"Split %d accuracy is: %s\" % (i,str(accuracy)))\n",
        "        i = i + 1\n",
        "    return sum(accuracy) / len(accuracy)"
      ],
      "metadata": {
        "id": "KSufWISYiCtO"
      },
      "id": "KSufWISYiCtO",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = KFOLD(model, loss, optimizer, dataset, k=3)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "FTbJ1IWvFSD8",
        "outputId": "7a979fdd-9d3b-497b-c7d2-933a198862c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "id": "FTbJ1IWvFSD8",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-82ea1224d30e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFOLD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-5812b40a9075>\u001b[0m in \u001b[0;36mKFOLD\u001b[0;34m(model, loss, optimizer, dataset, k)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mmean_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Split %d accuracy is: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-4b8f8f51394f>\u001b[0m in \u001b[0;36mtest_cycle\u001b[0;34m(test_dataloader, model)\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mpred_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mlabel_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0macc_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mmean_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'batch_size_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7392af7-d2df-47ce-befb-40925d96eea0",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "b7392af7-d2df-47ce-befb-40925d96eea0",
        "outputId": "6e0f3863-88e6-419a-b9d3-0854aeb63f92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Epoch: 1\n",
            "Epoch: 2\n",
            "Epoch: 3\n",
            "Epoch: 4\n",
            "Time passed: 46.121175050735474\n",
            "[tensor(4.2936, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2880, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2848, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2821, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2792, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2738, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2704, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2692, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2651, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2619, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2595, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2549, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2525, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2505, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2428, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2419, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2371, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2359, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2312, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2264, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2245, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2216, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2149, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2113, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2051, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.2038, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.1971, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.1951, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.1882, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.1852, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.1824, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.1715, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.1688, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.1644, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.1599, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.1560, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.1501, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.1421, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.1368, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.1307, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.1276, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.1193, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.1145, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.1078, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.1005, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.0972, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.0898, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.0824, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.0763, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.0733, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.0616, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.0549, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.0492, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.0401, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.0296, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.0236, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.0146, device='cuda:0', grad_fn=<DivBackward0>), tensor(4.0078, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.9969, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.9916, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.9848, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.9736, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.9651, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.9510, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.9451, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.9317, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.9236, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.9189, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.9096, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.8929, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.8922, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.8786, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.8613, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.8542, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.8402, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.8287, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.8225, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.8129, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.7986, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.7885, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.7838, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.7684, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.7566, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.7386, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.7350, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.7104, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.6967, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.6901, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.6845, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.6663, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.6549, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.6467, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.6297, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.6175, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.6053, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.5974, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.5765, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.5752, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.5501, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.5428, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.5329, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.5166, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.5041, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.4957, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.4942, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.4785, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.4616, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.4450, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.4333, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.4331, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.4264, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.4034, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.3906, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.3710, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.3631, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.3540, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.3479, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.3352, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.3163, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.3136, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.2965, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.2883, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.2690, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.2791, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.2695, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.2512, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.2337, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.2381, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.2218, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.2121, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.1954, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.1936, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.1897, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.1883, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.1801, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.1615, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.1579, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.1437, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.1479, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.1312, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.1398, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.1355, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.1159, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.1120, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0909, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.1085, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0972, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0991, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0756, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0837, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0920, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0907, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0889, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0751, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0525, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0610, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0434, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0429, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0211, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0431, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0291, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0313, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0076, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0148, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0143, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0134, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0047, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9995, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0002, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0004, device='cuda:0', grad_fn=<DivBackward0>), tensor(3.0104, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9909, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9938, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9918, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9914, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9648, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9749, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9747, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9809, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9659, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9695, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9784, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9737, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9690, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9651, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9741, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9684, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9593, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9247, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9456, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9320, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9334, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9597, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9541, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9133, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9385, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9367, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9082, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9193, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9246, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9089, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9308, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9248, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9027, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9247, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9487, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9335, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9246, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9095, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9300, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8944, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8848, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9080, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9162, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9073, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8969, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9143, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8927, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8890, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8907, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9020, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8766, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9123, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8757, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8828, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8887, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8777, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8785, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8771, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9140, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.9067, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8886, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8733, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8697, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8879, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8985, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8746, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8717, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8492, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8576, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8823, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8637, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8692, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8538, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8697, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8463, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8540, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8423, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8847, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8962, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8479, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8333, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8527, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8394, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8336, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8261, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8336, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8359, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8479, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8398, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8322, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8402, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8302, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8435, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8283, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8458, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8473, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8241, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8263, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8099, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8450, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8304, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8436, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8180, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8287, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8585, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8612, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8494, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8458, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8310, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8403, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8205, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8288, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7992, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8236, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8229, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8265, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7999, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8101, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8125, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8097, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8040, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8017, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8108, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8087, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8232, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8051, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8173, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8194, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8202, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7926, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8020, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8003, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8172, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8044, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8074, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8210, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8132, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8125, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8035, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8134, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8164, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8017, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7681, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7910, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7754, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7711, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.8031, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7908, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7535, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7879, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7792, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7494, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7592, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7687, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7516, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7748, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7650, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7467, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7701, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7994, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7850, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7776, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7594, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7831, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7470, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7362, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7566, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7651, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7617, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7505, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7710, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7446, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7409, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7426, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7527, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7203, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7610, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7277, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7265, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7384, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7270, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7272, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7273, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7677, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7632, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7343, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7149, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7133, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7296, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7392, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7140, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7112, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6924, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7067, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7251, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6993, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7070, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6942, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7092, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6852, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6927, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6848, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7292, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.7451, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6785, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6664, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6842, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6717, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6600, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6567, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6648, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6564, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6754, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6667, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6617, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6775, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6625, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6701, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6556, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6716, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6755, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6497, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6505, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6359, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6789, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6570, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6693, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6387, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6480, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6915, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6876, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6630, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6653, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6537, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6597, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6433, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6590, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6219, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6420, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6450, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6507, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6175, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6306, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6325, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6221, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6178, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6150, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6280, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6248, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6356, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6234, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6451, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6482, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6470, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6171, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6207, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6178, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6423, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6350, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6341, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6535, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6389, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6416, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6244, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6328, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6451, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6216, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5912, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6120, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5940, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5830, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6206, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6055, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5694, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6115, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5928, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5611, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5684, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5812, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5657, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5871, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5730, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5591, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5831, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6174, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6055, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5995, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5822, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6014, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5671, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5599, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5752, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5812, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5868, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5751, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5989, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5649, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5622, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5609, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5729, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5324, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5756, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5494, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5395, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5585, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5493, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5478, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5491, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5957, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5931, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5481, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5276, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5296, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5418, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5522, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5255, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5214, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5121, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5323, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5426, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5100, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5231, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5110, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5249, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5029, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5126, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5109, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5536, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5767, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4906, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4812, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4943, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4884, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4712, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4735, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4799, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4659, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4888, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4807, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4838, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5091, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4875, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4877, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4778, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4903, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5032, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4727, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4709, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4632, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5135, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4863, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5001, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4614, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4717, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5290, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5191, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4829, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4939, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4829, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4886, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4816, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5060, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4556, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4748, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4829, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4929, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4526, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4706, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4753, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4574, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4543, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4525, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4705, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4650, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4723, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4718, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5020, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5065, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5035, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4723, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4699, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4672, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5028, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5036, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4994, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5272, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5027, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5134, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4843, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4940, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5148, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4858, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4588, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4776, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4579, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4416, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4845, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4703, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4336, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4860, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4587, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4282, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4308, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4467, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4366, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4567, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4409, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4311, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4548, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4935, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4848, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4815, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4667, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4808, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4505, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4486, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4588, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4609, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4773, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4654, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4934, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4544, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4524, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4475, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4613, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4184, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4609, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4397, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4257, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4497, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4432, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4426, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4431, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4972, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4961, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4398, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4188, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4221, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4353, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4468, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4166, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4121, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4107, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4355, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4418, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4046, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4210, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4088, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4221, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4026, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4161, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4172, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4614, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4900, device='cuda:0', grad_fn=<DivBackward0>)]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "EPOCHS = 5\n",
        "losses = train_cycle(EPOCHS, train_dataloader, model, loss, optimizer)\n",
        "\n",
        "end = time.time()\n",
        "print(\"Time passed: \" + str(end - start))\n",
        "print(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ca5fda5-8841-4f0f-bacd-27f3c6ec365a",
      "metadata": {
        "id": "4ca5fda5-8841-4f0f-bacd-27f3c6ec365a",
        "outputId": "427207eb-a5eb-442e-a29b-b824ba96b284"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean accuracy is: 0.2651143695014595\n"
          ]
        }
      ],
      "source": [
        "print(\"Mean accuracy is: \" + str(sum(accuracies)/len(accuracies)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0933354f-a73b-429c-8cd3-3a3e9935205e",
      "metadata": {
        "id": "0933354f-a73b-429c-8cd3-3a3e9935205e"
      },
      "outputs": [],
      "source": [
        "# this function encoded a string as an input fitting for the NN of size (SxN)\n",
        "# * N = number of classes\n",
        "# * S = length of the string (in terms of characters)\n",
        "def generate_phrase_to_NN_input(num_classes, dictionary, device):\n",
        "    # input: a string\n",
        "    # output: a Sx72 one-hot tensor\n",
        "    def phrase_to_NN_input(phrase):\n",
        "        result = []\n",
        "        for char in phrase:\n",
        "            word_converted = torch.zeros(num_classes)\n",
        "            word_index = dictionary.loc[dictionary['data'] == char]['int_encoding'].item()\n",
        "            word_converted[word_index] = 1\n",
        "            result.append(word_converted)\n",
        "        result = torch.stack(result)\n",
        "        result = result.to(device)\n",
        "        return result\n",
        "    return phrase_to_NN_input\n",
        "phrase_to_NN_input = generate_phrase_to_NN_input(72,dictionary, gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edd1f5fd-6114-4788-9cbf-0bcf092dfd9f",
      "metadata": {
        "id": "edd1f5fd-6114-4788-9cbf-0bcf092dfd9f"
      },
      "outputs": [],
      "source": [
        "# this function decodes a string expressed as a tensor of shape SxN with values x\\in{0,1}, to a string of length S\n",
        "def generate_NN_output_to_phrase(num_classes, dictionary, device):\n",
        "    # input: a string\n",
        "    # output: a Sx72 one-hot tensor\n",
        "    def NN_output_to_phrase(nn_output):\n",
        "        result = \"\"\n",
        "        for tensor_hot_enc in nn_output:\n",
        "            idx_word = torch.argmax(tensor_hot_enc).item()\n",
        "            char_decoded = dictionary.loc[dictionary['int_encoding'] == idx_word]['data'].item()\n",
        "            result = result + char_decoded\n",
        "        return result\n",
        "    return NN_output_to_phrase\n",
        "NN_output_to_phrase = generate_NN_output_to_phrase(72,dictionary, gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3a98ced-b50d-4cd0-a3fe-cc14c53b822b",
      "metadata": {
        "id": "f3a98ced-b50d-4cd0-a3fe-cc14c53b822b"
      },
      "outputs": [],
      "source": [
        "wordminusminus_encoded = phrase_to_NN_input(\"--\")\n",
        "assert wordminusminus_encoded[0][4].item() == 1.0 and wordminusminus_encoded[1][4].item() == 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4b5b946-7cdf-4443-bae4-effa8c835bb5",
      "metadata": {
        "id": "c4b5b946-7cdf-4443-bae4-effa8c835bb5"
      },
      "outputs": [],
      "source": [
        "wordminusminus_decoded = NN_output_to_phrase(wordminusminus_encoded)\n",
        "assert wordminusminus_decoded == \"--\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d76b5a50-34e5-4794-9671-e097ceefc607",
      "metadata": {
        "id": "d76b5a50-34e5-4794-9671-e097ceefc607",
        "outputId": "0b26cc2c-237d-47b8-b1d5-598b23446ce8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ua ua ua                                  \n"
          ]
        }
      ],
      "source": [
        "phrase = \"eqweqweqwaaIII--------IIIIIaaaaaAAAAAAAAAAA\"\n",
        "phrase_encoded = phrase_to_NN_input(phrase)\n",
        "prediction = model([phrase_encoded])\n",
        "prediction_decoded = NN_output_to_phrase(prediction[0])\n",
        "print(prediction_decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b3a4c19-f51e-4128-ac7a-c7a56707889d",
      "metadata": {
        "id": "1b3a4c19-f51e-4128-ac7a-c7a56707889d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ba586a9-53eb-4910-9176-5a78834666c9",
      "metadata": {
        "id": "8ba586a9-53eb-4910-9176-5a78834666c9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3052c83b-65ec-4f6f-8f4d-9bf929d961f1",
      "metadata": {
        "id": "3052c83b-65ec-4f6f-8f4d-9bf929d961f1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f29abaef-4933-4993-81c1-f09fcd7bd245",
      "metadata": {
        "id": "f29abaef-4933-4993-81c1-f09fcd7bd245"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "711424b6-f454-4104-a5d9-4aaf07dff976",
      "metadata": {
        "id": "711424b6-f454-4104-a5d9-4aaf07dff976",
        "outputId": "3e5e72c1-b09c-495d-df74-9141f94ac4d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.08"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iterator = iter(test_dataloader)\n",
        "data, label = next(iterator)\n",
        "prediction = torch.stack(model(data))\n",
        "data_arg = torch.argmax(softmax(prediction).reshape(100,72),dim=1)\n",
        "label_arg = torch.argmax(torch.stack(label).reshape(100,72),dim=1)\n",
        "sum(torch.eq(data_arg, label_arg).tolist())/100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d896b35-c1df-4e11-ba67-e447cc56a858",
      "metadata": {
        "id": "1d896b35-c1df-4e11-ba67-e447cc56a858"
      },
      "outputs": [],
      "source": [
        "37.65237474441528"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4747ae41-9ad7-445a-aff3-16cf86eee6b4",
      "metadata": {
        "id": "4747ae41-9ad7-445a-aff3-16cf86eee6b4",
        "outputId": "05ac5f77-0c40-42c9-d2b9-c4456b5d6c15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [2, 3]])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([[1,2],[2,3]])\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7570f972-8951-44e7-9957-1e7dfd78df77",
      "metadata": {
        "id": "7570f972-8951-44e7-9957-1e7dfd78df77"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "a = torch.tensor([2.0], requires_grad=True)\n",
        "b = torch.tensor([3.0], requires_grad=True)\n",
        "\n",
        "c = 0\n",
        "for i in range(3):\n",
        "    c = c + a\n",
        "    print(c)\n",
        "\n",
        "c = c + torch.log(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8684f5bc-1489-40ad-8cc2-860c279bb1fe",
      "metadata": {
        "id": "8684f5bc-1489-40ad-8cc2-860c279bb1fe"
      },
      "outputs": [],
      "source": [
        "c.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09bf2ee8-73f0-4f14-8600-1c8717c2aff6",
      "metadata": {
        "id": "09bf2ee8-73f0-4f14-8600-1c8717c2aff6",
        "outputId": "213d945b-6f5f-4782-b0ed-7927a08fa08c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([3.])\n",
            "tensor([0.3333])\n"
          ]
        }
      ],
      "source": [
        "print(a.grad)\n",
        "print(b.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb2664bb-648f-4fd6-828e-a0662835455e",
      "metadata": {
        "id": "bb2664bb-648f-4fd6-828e-a0662835455e",
        "outputId": "00ee394f-595b-450f-b4a4-3ad954546f2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(2.0, shape=(), dtype=float32)\n",
            "tf.Tensor(4.0, shape=(), dtype=float32)\n",
            "tf.Tensor(6.0, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "a = tf.Variable(2.0)\n",
        "b = tf.Variable(3.0)\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    c = 0\n",
        "    for i in range(3):\n",
        "        c = c + a\n",
        "        print(c)\n",
        "\n",
        "    c = c + tf.math.log(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e551091d-c108-4f86-a501-8edb76297de4",
      "metadata": {
        "id": "e551091d-c108-4f86-a501-8edb76297de4",
        "outputId": "138d9e78-1c0b-4fc5-ea6a-da7d7a2fed82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=3.0>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.33333334>]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dy_da = tape.gradient(c, [a,b])\n",
        "dy_da"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f71d4ea-1743-4598-81db-d75c13eb932e",
      "metadata": {
        "id": "9f71d4ea-1743-4598-81db-d75c13eb932e",
        "outputId": "daf930d8-c0fa-4bf1-c82c-58ecd74f9935"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(7.0986123, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d268f1f2-31a2-4615-b5b9-0226ac2dbd78",
      "metadata": {
        "id": "d268f1f2-31a2-4615-b5b9-0226ac2dbd78",
        "outputId": "9aba31af-0987-4a49-9c21-7efd4c435ce2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  data  int_encoding\n",
            "0    a             0\n",
            "1    b             1\n",
            "2    c             2\n",
            "3    c             2\n",
            "4    a             0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "data = ('a','b','c','c','a')\n",
        "dictionary = pd.DataFrame(data, columns=['data'])\n",
        "\n",
        "dictionary['int_encoding'] = labelencoder.fit_transform(dictionary['data'])\n",
        "print(dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc175409-57af-405c-ad38-7067c4328edf",
      "metadata": {
        "id": "cc175409-57af-405c-ad38-7067c4328edf",
        "outputId": "48f370af-783b-46d6-f3f5-f030dcf6dbed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   int_encoding\n",
            "0             0\n",
            "1             1\n",
            "2             2\n",
            "3             2\n",
            "4             0\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "one_hot_enc = OneHotEncoder()\n",
        "one_hot = one_hot_enc.fit_transform(dictionary[['int_encoding']]).toarray()\n",
        "print(dictionary[['int_encoding']])\n",
        "print(one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2be69b90-b292-45d3-99f6-a44e8958b7d8",
      "metadata": {
        "id": "2be69b90-b292-45d3-99f6-a44e8958b7d8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "mat = torch.empty(5,100).to(gpu)\n",
        "for i in range(0, 1000000):\n",
        "    mat = torch.mm(mat, torch.transpose(mat,0,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c79497b9-91d0-4a01-9182-890cf48bd002",
      "metadata": {
        "id": "c79497b9-91d0-4a01-9182-890cf48bd002",
        "outputId": "eb603177-125e-4c8c-83b8-269956b9c84e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[6.6648e-10, 1.1040e-05, 2.6081e+20],\n",
            "        [2.0975e-07, 2.1876e-04, 4.3921e-05]])\n",
            "tensor([[6.6648e-10, 2.0975e-07],\n",
            "        [1.1040e-05, 2.1876e-04],\n",
            "        [2.6081e+20, 4.3921e-05]])\n",
            "tensor([[       inf, 1.1455e+16],\n",
            "        [1.1455e+16, 4.9784e-08]])\n"
          ]
        }
      ],
      "source": [
        "mat = torch.empty(2,3)\n",
        "a = torch.transpose(mat,0,1)\n",
        "print(mat)\n",
        "print(a)\n",
        "print(torch.mm(mat,a))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb623997-50f2-4101-b5a2-868ad99c05f8",
      "metadata": {
        "id": "fb623997-50f2-4101-b5a2-868ad99c05f8",
        "outputId": "9a9e3e40-5436-488c-84da-4fc2e313834b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.arange(10).reshape(5,2)\n",
        "a\n",
        "torch.split(a,1)\n",
        "a.size(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b437d3c0-c0af-4056-9f97-df3f1b08f17f",
      "metadata": {
        "id": "b437d3c0-c0af-4056-9f97-df3f1b08f17f",
        "outputId": "c9b40576-8ad2-4e89-979f-fb09557a2cca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1, 2])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[-0.1867, -0.5635]],\n",
              "\n",
              "        [[-0.5525, -0.4179]]])"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.stack([torch.randn((1,2)),torch.randn((1,2))])\n",
        "print(a.size())\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae95d04e-70c2-43cb-a1e1-d779812b9e3e",
      "metadata": {
        "tags": [],
        "id": "ae95d04e-70c2-43cb-a1e1-d779812b9e3e",
        "outputId": "f3e13702-4ee7-4042-dac4-5d74aa16266c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "128\n",
            "72\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "Dimension out of range (expected to be in range of [-3, 2], but got 3)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [97], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(b\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(b\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m)\n",
            "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-3, 2], but got 3)"
          ]
        }
      ],
      "source": [
        "a = next(iter(train_dataloader))\n",
        "b = torch.stack(a[0])\n",
        "print(b.size(0))\n",
        "print(b.size(1))\n",
        "print(b.size(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81b26756-03eb-4d3e-be09-e191cebf1602",
      "metadata": {
        "id": "81b26756-03eb-4d3e-be09-e191cebf1602",
        "outputId": "5b34649f-8fa5-4051-c6d2-d3c71c095957"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'softmax'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [91], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m pred \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m20\u001b[39m]),torch\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m10\u001b[39m])]\n\u001b[0;32m      4\u001b[0m softmax \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor([[\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],softmax(pred)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]],[softmax(pred)[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m],softmax(pred)[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]]])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m      7\u001b[0m loss(pred,label)\n",
            "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1376\u001b[0m, in \u001b[0;36mSoftmax.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1834\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1832\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1834\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m(dim)\n\u001b[0;32m   1835\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1836\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'softmax'"
          ]
        }
      ],
      "source": [
        "loss = torch.nn.CrossEntropyLoss()\n",
        "# pred=(a,c),(a,a), label=(a,b),(c,c)\n",
        "pred = [torch.FloatTensor([10,20]),torch.FloatTensor([20,10])\n",
        "softmax = torch.nn.Softmax(dim=0)\n",
        "label = torch.FloatTensor([[softmax(pred)[0][0],softmax(pred)[0][1]],[softmax(pred)[1][0],softmax(pred)[1][1]]])\n",
        "print(pred.size())\n",
        "loss(pred,label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d0d1d66-d815-4641-8394-f61d51f43974",
      "metadata": {
        "id": "9d0d1d66-d815-4641-8394-f61d51f43974",
        "outputId": "925453e1-baf8-4c8c-c94c-cc9fcfc3a52a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([6.])"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.ones(1, requires_grad=True)\n",
        "y = x**2\n",
        "z = x**3\n",
        "w = x**3\n",
        "z.backward()\n",
        "w.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e53b4bbf-6021-4c27-b87c-d7b797353bb7",
      "metadata": {
        "id": "e53b4bbf-6021-4c27-b87c-d7b797353bb7",
        "outputId": "8cf80410-f298-45ef-b2ad-07d73f3d7793"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [17], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m target \u001b[38;5;241m=\u001b[39m tensor([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m      3\u001b[0m preds \u001b[38;5;241m=\u001b[39m tensor([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtorchmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAccuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmulticlass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m accuracy(preds, target)\n",
            "File \u001b[1;32mD:\\Programmi\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchmetrics\\classification\\accuracy.py:490\u001b[0m, in \u001b[0;36mAccuracy.__new__\u001b[1;34m(cls, threshold, num_classes, average, mdmc_average, ignore_index, top_k, multiclass, subset_accuracy, task, num_labels, multidim_average, validate_args, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(num_classes, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m--> 490\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(top_k, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MulticlassAccuracy(num_classes, top_k, average, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "\u001b[1;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from torch import tensor\n",
        "target = tensor([0, 1, 2, 3])\n",
        "preds = tensor([0, 2, 1, 3])\n",
        "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=4)\n",
        "accuracy(preds, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a94f05d-8a65-4e46-af34-13c6c7de5229",
      "metadata": {
        "id": "4a94f05d-8a65-4e46-af34-13c6c7de5229"
      },
      "outputs": [],
      "source": [
        "y = torch.tensor([\n",
        "     [\n",
        "       [1, 0, 0],\n",
        "       [1, 0, 0]\n",
        "     ],\n",
        "     [\n",
        "       [0, 1, 0],\n",
        "       [0, 0, 1]\n",
        "     ],\n",
        "     [\n",
        "       [0, 0, 1],\n",
        "       [0, 0, 1]\n",
        "     ]\n",
        "   ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73572edf-58fa-4377-a1de-63edd46e23ce",
      "metadata": {
        "id": "73572edf-58fa-4377-a1de-63edd46e23ce",
        "outputId": "0f5853c3-3379-479c-85fb-c3fbd34e68b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 2, 3])"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f3b11e1-caf8-4666-adb9-c5edb2444d78",
      "metadata": {
        "id": "9f3b11e1-caf8-4666-adb9-c5edb2444d78",
        "outputId": "46fb6d68-ae0c-4ef2-f2ad-395bbc6808e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0, 0],\n",
              "        [1, 2],\n",
              "        [2, 2]])"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.argmax(y.float(),dim=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a41635f7-8e0e-4a9b-a393-ba0ae1f05974",
      "metadata": {
        "id": "a41635f7-8e0e-4a9b-a393-ba0ae1f05974",
        "outputId": "ddf72c4d-a94f-4237-91e7-5b27ecb170e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        data  int_encoding\n",
            "0          b            39\n",
            "1          e            42\n",
            "2          n            51\n",
            "4                        1\n",
            "6          u            58\n",
            "...      ...           ...\n",
            "1099082    -             4\n",
            "1099618    U            33\n",
            "1100751    È            64\n",
            "1101278    N            26\n",
            "1104174    V            34\n",
            "\n",
            "[72 rows x 2 columns]\n",
            "72\n",
            "39\n"
          ]
        }
      ],
      "source": [
        "print(dictionary)\n",
        "print(len(dictionary))\n",
        "a = dictionary.loc[dictionary['data'] == 'b']['int_encoding']\n",
        "print(a[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d88a0ea-e6fc-40f2-8f7f-180d66d65557",
      "metadata": {
        "id": "1d88a0ea-e6fc-40f2-8f7f-180d66d65557"
      },
      "source": [
        "##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b017161f-557e-4242-b603-f587262a76d3",
      "metadata": {
        "id": "b017161f-557e-4242-b603-f587262a76d3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}